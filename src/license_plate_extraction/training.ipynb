{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This checks if\n",
    "# (a) the code is running in google colab\n",
    "# (b) the repository hasn't been cloned yet\n",
    "import sys\n",
    "from pathlib import Path\n",
    "if \"google.colab\" in sys.modules:\n",
    "    target_path = Path(\"/content/license_plate_detection/src/license_plate_extraction\")\n",
    "    if not target_path.exists():\n",
    "        !git clone https://github.com/cxan96/license_plate_detection /content/license_plate_detection/\n",
    "    %cd $str(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses\n",
    "import numpy as np\n",
    "from data_reader import get_image_paths_from_directory, make_dataset_from_image_paths\n",
    "from preprocessing import bounding_box_in_pixel\n",
    "from visualization_tools import show_image\n",
    "import data_augmentation\n",
    "import settings\n",
    "import models\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all the available images into a list of paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory_eu = settings.DATA_DIR / \"eu_cars+lps\"\n",
    "image_directory_br = settings.DATA_DIR / \"br_cars+lps\"\n",
    "image_directory_us = settings.DATA_DIR / \"us_cars+lps\"\n",
    "image_directory_ro = settings.DATA_DIR / \"ro_cars+lps\"\n",
    "image_directory_russia = settings.DATA_DIR / \"cars_russia\"\n",
    "\n",
    "# make a list with all the image paths to use during training\n",
    "image_paths_train = np.array(\n",
    "    [\n",
    "        *get_image_paths_from_directory(image_directory_eu, contains=\"_car_\"),\n",
    "        *get_image_paths_from_directory(image_directory_br, contains=\"_car_\"),\n",
    "        *get_image_paths_from_directory(image_directory_us, contains=\"_car_\"),\n",
    "        *get_image_paths_from_directory(image_directory_ro, contains=\"_car_\"),\n",
    "        *get_image_paths_from_directory(image_directory_russia),\n",
    "    ]\n",
    ")\n",
    "\n",
    "validation_directory_eu = settings.DATA_DIR / \"validation_eu\"\n",
    "validation_directory_ro = settings.DATA_DIR / \"validation_ro\"\n",
    "\n",
    "# the image paths used for validation\n",
    "image_paths_test = np.array(\n",
    "    [\n",
    "        *get_image_paths_from_directory(validation_directory_eu, contains=\"_car_\"),\n",
    "        *get_image_paths_from_directory(validation_directory_ro, contains=\"_car_\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_images_train = len(image_paths_train)\n",
    "num_images_test = len(image_paths_test)\n",
    "\n",
    "print(f\"Number of training images = {num_images_train}\")\n",
    "print(f\"Number of test images = {num_images_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training set as well as the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_IMG_HEIGHT = 400\n",
    "TARGET_IMG_WIDTH = 400\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset_train = make_dataset_from_image_paths(\n",
    "    image_paths_train,\n",
    "    target_img_height=TARGET_IMG_HEIGHT,\n",
    "    target_img_width=TARGET_IMG_WIDTH,\n",
    ")\n",
    "\n",
    "# add data augmentation\n",
    "dataset_train = data_augmentation.horizontal_flip(dataset_train)\n",
    "# dataset_train = data_augmentation.add_brightness(dataset_train)\n",
    "# dataset_train = data_augmentation.add_contrast(dataset_train)\n",
    "\n",
    "# set batch size\n",
    "dataset_train = dataset_train.shuffle(1024).batch(BATCH_SIZE)\n",
    "\n",
    "dataset_test = make_dataset_from_image_paths(\n",
    "    image_paths_test,\n",
    "    target_img_height=TARGET_IMG_HEIGHT,\n",
    "    target_img_width=TARGET_IMG_WIDTH,\n",
    ")\n",
    "dataset_test = dataset_test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(input_height, input_width, num_channels):\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(input_height, input_width, num_channels)),\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(\n",
    "                1.0 / 255,\n",
    "            ),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(4, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = simple_model(\n",
    "    input_height=TARGET_IMG_HEIGHT, input_width=TARGET_IMG_WIDTH, num_channels=3\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=losses.MAE, metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir $settings.LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Tensorboard callback\n",
    "log_dir = settings.LOG_DIR / (\n",
    "    \"training_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    ")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1, update_freq=\"batch\"\n",
    ")\n",
    "\n",
    "# this makes sure the model is regularly saved to not lose any progress made during training\n",
    "epochs_per_checkpoint = 5\n",
    "class ModelSaveCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > 1 and epoch % epochs_per_checkpoint == 0:\n",
    "            cur_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            model.save(f\"{cur_time}_epoch_{epoch}.tf\")\n",
    "            print(\"Saved results!\")\n",
    "\n",
    "\n",
    "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\"checkpoint_epoch_{epoch}.tf\")\n",
    "\n",
    "model.fit(\n",
    "    dataset_train,\n",
    "    epochs=1000,\n",
    "    validation_data=dataset_test,\n",
    "    callbacks=[tensorboard_callback, ModelSaveCallback()],\n",
    ")"
   ]
  },
  {
   "source": [
    "Evaluate the model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_list = list(dataset_test.as_numpy_iterator())\n",
    "\n",
    "for cur_example in example_list:\n",
    "    cur_image_batch = cur_example[0]\n",
    "    cur_prediction_batch = model.predict(cur_image_batch)\n",
    "    \n",
    "    for cur_image, cur_prediction in zip(cur_image_batch, cur_prediction_batch):\n",
    "        print(cur_prediction)\n",
    "        \n",
    "        show_image(\n",
    "            cur_image.astype(int),\n",
    "            bounding_box=bounding_box_in_pixel(\n",
    "                cur_prediction,\n",
    "                img_height=TARGET_IMG_HEIGHT,\n",
    "                img_width=TARGET_IMG_WIDTH,\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}